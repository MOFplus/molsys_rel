#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""test script to optimize all systems in the DB

all systems with zero energy and not TS are picked and optimized
"""

import pylmps
import molsys
import sys
import os
import time
import numpy as np
import ast
from molsys.util import RDB
from molsys.util import turbomole

#
# class defintions 
#
class turbomole_calculator:

    def __init__(self, params : dict):
       # sanity checks
       assert "submit" in params, "To submit or not to submit? That is the queuing question."

       # lot should be set as specified in the Tmole manual
       # R. Ahlrichs et al., “Chapter 3.3 Running Turbomole using the script TMOLE,” in
       # Turbomole User’s Manual Version 6.0, 2009, pp. 38–44
       # https://www.cms.hu-berlin.de/de/dl/systemservice/computeservice/docs/turbo58_html
       # 
       # TODO the turbomole module needs generalization...
       lot_DFT = params["lot"]

       # get the current working directory
       self.maindir = os.getcwd()

       # if a path for the data is not assigned, set the current working directory for that
       self.data_dir = params["data_storage_path"]

       # create a DFT folder with the name of the method
       dft_functional = lot_DFT.split("/")[0]
       basis_set = lot_DFT.split("/")[1]
       dft_dir_name = "-".join([dft_functional,basis_set])
       self.dft_path = os.path.join(self.data_dir, dft_dir_name)
       if not os.path.isdir(self.dft_path):
           os.mkdir(self.dft_path)

       # default parameters
       if "turbodir" not in params:
           params["turbodir"] = os.popen("echo $TURBODIR").read() 
       elif "max_mem" not in params:
           params["max_mem"] = 500

       # default parameters for job submission and set the other variables
       if params["submit"]:
           if "ntasks" not in params:
               params["ntasks"] = 8
           elif "partition" not in params:
               params["partition"] = "normal" 
           elif "maxnodes" not in params:
               params["maxnodes"] = 4
           # write the SLURM job submission script 'submit.sh' to the QM calculation home directory 
           turbomole.Slurm.write_submission_script(self.dft_path, params["turbodir"], params["ntasks"], params["partition"])
           CPUS, MEM = turbomole.Slurm.get_partition_info(params["partition"])
           MEM_per_CPU = MEM/CPUS
           params["max_mem"] = 0.8*MEM_per_CPU
           njobs_per_node = CPUS/params["ntasks"]
           self.max_njobs = int(params["maxnodes"]*njobs_per_node)
       self.params = params
       return

    def make_dft_subdir(self, reactionID, db_path):
       # Create the subdirectory for the DFT calculation
       subdir_name = 'from_reaction_%05d' % reactionID
       dft_subdir_path = os.path.abspath(os.path.join(self.dft_path, subdir_name))
       exists = os.path.isdir(dft_subdir_path)
       if not exists:
           os.mkdir(dft_subdir_path)          
       return dft_subdir_path, exists


    def optimize(self, reactionID, dft_subdir_path, rbonds = [], path_ref_educts = [], path_ref_products = [], path_ref_ts = '',  atom_ids_dict = {}):
       # initialize the OptimizationTools class from the turbomole module under molsys/util/turbomole.py

       OT = turbomole.OptimizationTools(path = dft_subdir_path, lot = self.params["lot"], max_mem = self.params["max_mem"])

       if self.params["submit"] == False:
           OT.reaction_workflow(rbonds, path_ref_educts, path_ref_products, path_ref_ts, atom_ids_dict)
       else:
           OT.write_submit_py(rbonds, path_ref_educts, path_ref_products, path_ref_ts, atom_ids_dict)
           #submit the job to the SLURM queuing system and get the assigned job id
           os.chdir(dft_subdir_path)
           sbatchout = os.popen("sbatch -J r.%d %s" %(reactionID, os.path.join(self.dft_path,"submit.sh"))).read()
#           sbatchout = os.popen("sbatch -J r.%d --reservation oyoender_7 %s" %(reactionID, os.path.join(self.dft_path,"submit.sh"))).read()
           jobid = sbatchout.split()[3]
           os.chdir(self.maindir)
       return jobid

    def get_multiplicity(dft_subdir_path):
       """ Calculate the spin multiplicity from the ridft output.
       """
       GT = turbomole.GeneralTools(dft_subdir_path)
       nalpha, nbeta = GT.get_nalpha_and_nbeta_from_ridft_output()
       M = GT.calculate_spin_multiplicity_from(nalpha, nbeta) 
       return M

    def get_energy(dft_subdir_path, atom):       
       """ Read the energy from the aoforce output (or from the ridft output for atoms).
       SPE: float : Single point energy
       ZPE: float : Zero point vibrational energy
       """
       GT = turbomole.GeneralTools(dft_subdir_path)
       if atom:
           SPE = GT.get_energy_from_ridft_out()
           ZPE = 0.0
       else:
           SPE, ZPE = GT.get_energy_from_aoforce_out() 
       return  SPE, ZPE

    def get_mol(dft_subdir_path):
       os.system("t2x %s/coord > %s/coord.xyz" %(dft_subdir_path, dft_subdir_path))
       mol = molsys.mol.from_file(os.path.join(dft_subdir_path,"coord.xyz"))
       return mol




#
# Helper functions
#
def get_mol_from_opt_spec(ospec):
    # get mol object from DB
    fname, mfpxf = db.opt_species.mfpx.retrieve(ospec.mfpx)
    mfpxs = mfpxf.read().decode('utf-8')
    mfpxf.close()
    mol = molsys.mol.from_string(mfpxs)
    mol.addon("graph")
    mol.detect_conn()
    mol.graph.make_graph()
    return mol

def get_opt_spec_path(ospec):
    fname, mfpxf = db.opt_species.mfpx.retrieve(ospec.mfpx)
    ospec_mfpxf_path = mfpxf.name
    mfpxf.close()
    return ospec_mfpxf_path

def get_md_spec_mfpx(md_spec):
    fname, mfpxf = db.md_species.mfpx.retrieve(md_spec.mfpx)
    md_spec_mfpxf_path = mfpxf.name
    mfpxf.close()
    return md_spec_mfpxf_path

def get_ncurjobs(jobids):
    squeueout = os.popen('squeue --format="%A"').read()
    squeuelist=squeueout.split()
    curjobids=set(jobids).intersection(squeuelist)
    ncurjobs = len(curjobids)
    return ncurjobs, curjobids



######################################################################################################################
######################################################################################################################
#
# Start of main program 
#
if len(sys.argv) < 6:
    print ("usage:  opt_md_species <db_path> <pdlp_file> <stage> <start_lot> <cmd_file>")
    exit()
    

db_path   = sys.argv[1]
pdlp_path = sys.argv[2]
pdlp_path = os.path.abspath(pdlp_path)
stage     = sys.argv[3]
start_lot = sys.argv[4]
cmd_file  = sys.argv[5]

assert os.path.isfile(cmd_file), "command file exists!"

print ("open database %s" % db_path)
rdb = RDB.RDB(db_path)
print ("dealing with MD from file %s and stage %s"  % (pdlp_path, stage))

# get all entries in md_species not TS (access pydal  directly TBI: some clever routines in rdb to handle this)
db = rdb.db
md = db((db.md.path == pdlp_path) & (db.md.stage == stage)).select().first()

reactions = db(db.reactions).select() 

start_lotID = rdb.get_lot(start_lot)

# read param set. Examples are:
# ------------------------------
# DFT could look like
#params = { "calculator"        : "turbomole"
#         , "data_storage_path' : "/home/oyoender/DATA/"
#         , "lot"               : "ri-utpss/SVP"
#         , "max_mem"           : 3000
#         , "submit"            : True
#         , "turbodir"          : "/opt/software/user-soft/turbomole/75"
#         , "ntasks"            : 8
#         , "maxnodes"          : 4
#         , "partition"         : "normal"
#         }

file = open(cmd_file, "r")
content = file.read()
params = ast.literal_eval(content)

# sanity check(s)
assert "calculator" in params, "Calculator defined"
assert "lot" in params, "Level of theory is given for the calculator"
assert "data_storage_path" in params, "The path to where to store the data is given"

if params["calculator"] == "turbomole":
    calculator = turbomole_calculator(params)

lotID = rdb.get_lot(params["lot"])

curjobids = []
ncurjobs = 0
jobids = []

# Loop over the reactions
'''
path_ref_educts   : list   : the mfpx path of the educts from the start LOT
path_ref_products : list   : the mfpx path of the products from the start LOT
path_ref_ts       : string : the mfpx path of the TS from the start LOT
path_ed_complex   : string : the mfpx path of the educt complex from MD for non-unimolecular rxns
path_prod_complex : string : the mfpx path of the product complex from MD for non-unimolecular rxns
'''
for r in reactions:
    if r.id != 1:
        # get all species for this reaction
        reac2ts_spec = db((db.reac2spec.reactionsID == r) & (db.reac2spec.label ==  0)).select().first()
        reac2educt_spec = db((db.reac2spec.reactionsID == r) & (db.reac2spec.label == -1)).select()
        reac2prod_spec  = db((db.reac2spec.reactionsID == r) & (db.reac2spec.label ==  1)).select()
        n_ed = len(reac2educt_spec)
        n_prod = len(reac2prod_spec)
    
        # Check if the reaction is unimolecular or not.
        if n_ed == 1 and n_prod == 1:
            unimolecular = True
            uni_equal = molsys.addon.graph.is_equal(mol_ed_ref.graph.molg, mol_prod_ref.graph.molg)
            if uni_equal[0]:
                 print('The graph of the initial and final structure of the reaction %d at level of theory %s is the same.' %(r.id, start_lot))
        else:
            unimolecular = False

        # 1) Get the reference structures from the startLOT for the further optimizations
        # educts
        path_ref_educts = []
        for i,ed in enumerate(reac2educt_spec):
            ed_ref = db((db.opt_species.speciesID == ed.speciesID) & (db.opt_species.lotID == start_lotID)).select().first()
            mol_ed_ref = get_mol_from_opt_spec(ed_ref)
            path_ref_educts.append(get_opt_spec_path(ed_ref))    
        # products
        path_ref_products = []
        for i,prod in enumerate(reac2prod_spec):
            prod_ref = db((db.opt_species.speciesID == prod.speciesID) & (db.opt_species.lotID == start_lotID)).select().first()
            mol_prod_ref = get_mol_from_opt_spec(prod_ref)
            path_ref_products.append(get_opt_spec_path(prod_ref))
        # transition state
        ts_ref =  db((db.opt_species.speciesID == reac2ts_spec.speciesID) & (db.opt_species.lotID == start_lotID)).select().first()
        path_ref_ts = get_opt_spec_path(ts_ref)
        # store the indices as of from MD simulation to extract the atoms which belong to educts or products from the TS structure
        # this is needed if woelfling calculation is necessary
        revent    = db( db.revent.reactionsID == r.id ).select().first()
        md_ed_species   = db((db.md_species.reventID == revent.id) & (db.md_species.foffset == -1)& (db.md_species.react_compl == False)).select()
        md_prod_species = db((db.md_species.reventID == revent.id) & (db.md_species.foffset == 1)& (db.md_species.react_compl == False)).select()
        md_ts = db((db.md_species.reventID == revent.id) & (db.md_species.foffset == 0)).select().first()
        atom_ids_dict = {'ts':md_ts.atomids}
        for i,spec in enumerate(md_ed_species):
            atom_ids_dict['educt_%d' %(i+1)] = spec.atomids
        for i,spec in enumerate(md_prod_species):
            atom_ids_dict['product_%d' %(i+1)] = spec.atomids

        # Get the information on reactive bonds
        rbonds = ts_ref["rbonds"]
        
        if params["calculator"] == "turbomole":
            if params["submit"]:
                # submit the jobs to the specifies number of total cores.
                print(ncurjobs, calculator.max_njobs)
                while ncurjobs == calculator.max_njobs:
                    print("Maximum number of jobs running at the same time is reached. Waiting for the jobs %s to finish." %str(list(curjobids)))
                    time.sleep(30)
                    ncurjobs, curjobids = get_ncurjobs(jobids)
                # submit the job to the queue and get the job id from the queing system
 
                dft_subdir_path, exists = calculator.make_dft_subdir(r.id, db_path)
                if not exists:
                    jobid = calculator.optimize(r.id, dft_subdir_path, rbonds, path_ref_educts, path_ref_products, path_ref_ts, atom_ids_dict)
                    jobids.append(jobid)
                elif exists:
                    print('The directory %s already exists. Please, check if the directory contains the results.' %dft_subdir_path)
                ncurjobs, curjobids = get_ncurjobs(jobids)
            else:
                print("Not implemented yet.")
                exit()
